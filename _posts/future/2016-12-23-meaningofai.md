---
title: "The meaning of AI in the mirror of the future"
tags: [future]
---

### Introduction
Nowdays, we hear about AI on a regular base due to its fast development. A huge bunch of novels, films were written in connection with this strange part of the technology. Almost all of them grabs some negative sides of AI and paints a threathening picture about human's future. 

For instance Isaac Asimov's *I, robot* story showcases the failer the well-founded (it seems) three rules. 

![irobot](/images/irobot.jpg "I robot")

Lots of other films, books, novels were written in connection with AI and all of them ask some important questions to consider regarding the possible failures.  

This post put more ephasis on the potential benefits of AI. The covered themes are:

- scientific development
- potential risks for the human race and ai as a solution
- obstacles regarding computing power.

### Scientific development

In order to judge AI in a right way some inspection into the scientific background is useful. The term artificial intelligence was coined at the [Dartmouth Conference](https://en.wikipedia.org/wiki/Dartmouth_workshop) in 1956. On that conference a bunch of scientists (among them John McCarthy, Marvin Minsky, Nathaniel Rochester, Claude Shannon who were the fathers of ai) proposed ambitious goals like natural language processing, expert systems, neural networks, inferencing machines etc. Under these ambitions a tantalizing question lies: can a machine think? After the invention of the computer this is a natural claim and gives rise more other exciting questions: how does the human brain works?, what makes us human?, what does understanding mean?, is it possible to automatize research?, what is intelligence? and the list goes on. 

Despite the fact that investors more frequently admit AI is coming there is no accepted definition what does AI mean. This is because no one knows what is intelligence therefore how intelligence can be artificial. But we do not worry about this as Einstein's great line suggest:

> If we knew what it was we were doing, it would not be        
> called research, would it?    

Nowdays, most of the breakthroughs in AI is connected to machine learning. In fact, most of the algorithms, fields of AI were invented in the past decades (between 1950 and 1980). Of course, later other methods were ivestigated and older ones were refined but the core concepts were found back in the 60's. What really changed is the computing power. The old concepts with some refinement can achieve high and spectacular results on today's computing architectures. This phenomena causes the new wave of AI after the so called AI winter (about 1980-1990). Without much exaggeration nowdays AI is the synonym of machine learning (hereafter ML). This due to not just for ML is so successful but learning is a key feature of a true AI system. Without the ability of learning the system can not adapt to changes occured in its environment. Furthermore, humans learn **all** their intelligent capabilities during their lifetime. From this point of view learning becomes the corner stone of AI.

From the practical point of view, most of the problems we encounter, as humankind, is difficult to tackle on the traditional way. Traditional way means that our thinking process uses a somewhat sequental approach. We can describe the solution algorithm step by step and each step is feasable according to our knowledge. Programmatically this leads to the *imperative paradigm*. A lot of problem, for example recognizing someone or something, can not be solved by following this paradigm. A newer approach is the so called *declarative paradigm*. That means we precisely prescribe what conditions should be satisfied by the solution then find it by searching through a solution space (the set of all the algorithms). 

The possible success of this approach revolves around 3 things:

* Does the solution exist in the solution space?
* How many time is taken by the search? 
* How is the safety ensured for the resulted solution?

So, to get a working AI algorithm means the following. Use the declarative approach. Give a suitable solution space as ingredients to your learning algorithm, find the solution in a considerable time in it to the problem. The found solution should be safe as well. 

The main achivement is mostly the consequence of a good approach to the first problem. The so called artificial neural networks (ANNs) can provide a huge solution space that most of the time is enough to solve the problem. There is no strict mathematical background how the neural network should be formed for a given problem but thumb rules (special neural architectures) are gathered after experimental results over years. 

There exists a branch of ML, reinforcement learning, which uses interventions to enhance its strength and solve more complex problem sets (e.g.: learn to play Atari games from raw pixels, controlling robots etc.). This field has exceptionally strong mathematical basis even for the searching issues. 

Todays AI reasearch mainly focuses on the study of finding the right solution space (dimensionality reduction, expreiments with neural nets, complexity analysis etc.) and the study of ensuring the right speed of the search (heuristical search, monte carlo methods, planning etc.). But the last one is missing yet. Perheaps by developing better and better methods for the first and second may lead to a clue for the last one as well.    


### Potential risks

### Limits

This chapter should contain:

* computing power
* end of Moor's law?
* possible solution for enhance the power of computers
* current endevours

### AI is necessary


<a href="https://github.com/adamtiger/ai/tree/code" target="_blank" class="btn btn-success"><i class="fa fa-github fa-lg"></i> View on GitHub</a>
