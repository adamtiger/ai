---
title: "The meaning of AI in the mirror of the future"
tags: [future]
---

### Introduction
Nowadays, we hear about AI on a regular base due to its fast development. A huge bunch of novels, films were written in connection with this strange part of the technology. Almost all of them grabs some negative sides of AI and paints a threatening picture about human's future. 

For instance Isaac Asimov's *I, robot* story showcases the failure the well-founded (it seems) three rules. 

![irobot](/ai/images/irobot.jpg "I robot")

Lots of other films, books, novels were written in connection with AI and all of them ask some important questions to consider regarding the possible failures.  

This post put more emphasis on the potential benefits of AI. The covered themes are:

- scientific development
- potential risks for the human race and AI as a solution
- obstacles regarding computing power.

### Scientific development

In order to judge AI in a right way some inspection into the scientific background is useful. The term artificial intelligence was coined at the [Dartmouth Conference](https://en.wikipedia.org/wiki/Dartmouth_workshop) in 1956. On that conference a bunch of scientists (among them John McCarthy, Marvin Minsky, Nathaniel Rochester, Claude Shannon who were the fathers of AI) proposed ambitious goals like natural language processing, expert systems, neural networks, inferencing machines etc. Under these ambitions a tantalizing question lies: can a machine think? After the invention of the computer this is a natural claim and gives rise more other exciting questions: how does the human brain works?, what makes us human?, what does understanding mean?, is it possible to automates research?, what is intelligence? and the list goes on. 

Despite the fact that investors more frequently admit AI is coming there is no accepted definition what does AI mean. This is because no one knows what is intelligence therefore how intelligence can be artificial. But we do not worry about this as Einstein's great line suggests:

> If we knew what it was we were doing, it would not be        
> called research, would it?    

Nowadays, most of the breakthroughs in AI are connected to machine learning. In fact, most of the algorithms, fields of AI were invented in the past decades (between 1950 and 1980). Of course, later other methods were investigated and older ones were refined but the core concepts were found back in the 60's. What really changed is the computing power. The old concepts with some refinement can achieve high and spectacular results on today's computing architectures. This phenomenon causes the new wave of AI after the so called AI winter (about 1980-1990). Without much exaggeration nowadays AI is the synonym of machine learning (hereafter ML). This due to not just for ML is so successful but learning is a key feature of a true AI system. Without the ability of learning the system can not adapt to changes occurred in its environment. Furthermore, humans learn **all** their intelligent capabilities during their lifetime. From this point of view learning becomes the corner stone of AI.

From the practical point of view, most of the problems we encounter, as humankind, are difficult to tackle on the traditional way. Traditional way means that our thinking process uses a somewhat sequential approach. We can describe the solution algorithm step by step and each step is feasible according to our knowledge. Programmatically this leads to the *imperative paradigm*. A lot of problem, for example recognizing someone or something, can not be solved by following this paradigm. A newer approach is the so called *declarative paradigm*. That means we precisely prescribe what conditions should be satisfied by the solution then find it by searching through a solution space (the set of all the algorithms). 

The possible success of this approach revolves around 3 things:

* Does the solution exist in the solution space?
* How much time is consumed by the search? 
* How is the safety ensured for the resulted solution?

So, to get a working AI algorithm means the following. Use the declarative approach. Give a suitable solution space as ingredients to your learning algorithm; find the solution in a considerable time in it to the problem. The found solution should be safe as well. 

The main achievement is mostly the consequence of a good approach to the first problem. The so called artificial neural networks (ANNs) can provide a huge solution space that most of the time is enough to solve the problem. There is no strict mathematical background how the neural network should be formed for a given problem but thumb rules (special neural architectures) are gathered after experimental results over years. 

There exist a branch of ML, reinforcement learning, which uses interventions to enhance its strength and solve more complex problem sets (e.g.: learn to play Atari games from raw pixels, controlling robots etc.). This field has exceptionally strong mathematical basis even for the searching issues. 

Today's AI research mainly focuses on the study of finding the right solution space (dimensionality reduction, experiments with neural nets, complexity analysis etc.) and the study of ensuring the right speed of the search (heuristic search, monte carlo methods, planning etc.). But the last one is missing yet. Perhaps by developing better and better methods for the first and second issues may lead to a clue for the last one as well.    


### Potential risks

AI has the power to outperform humans in everything. This raises the concern that thinking machine could wipe out humans when they become conscious. It is difficult to disprove or confirm this because the technology has not invented yet. So most of these arguments are closer to sci-fi then reality. The importance of them is to draw some attention to safety which is a very important factor in the long run. 

In my opinion, the bigger problem is on the human side. A radical organization can use it to create weapons then lose control over them. The most crucial point regarding the future of AI is not the engineering issues, I am optimistic and I strongly believe AI will works within some decades, but how we will treat it and incorporate into our everyday lives.


### AI in the future

AI has short and long term benefits as well. In the short run AI can complete the tasks which currently suffer from the lack of human resources like health care, authorities, management etc. A lot of problems (scheduling the resources in a sustainable manner in the Earth, poverty, personal education instead of mass production) can be found around us which humans could solve but no enough capacity is available. Nowadays, our society handles these in the expense of quality because somewhat they are solved but in a worthless way.

It is true that some of the jobs which currently exist will disappear as AI is getting stronger and stronger but newer ones will arise and substitute them.

In the long run the benefits of AI are clearer. It can solve problems which are due to the large population; it can protect the Earth from external dangers coming from the space.

![colonize](/ai/images/coloniseSpace.jpg "Colonizing the space")

Our time is limited in the Earth because the sun will not keep shining forever. Therefore it is vital in the far future to colonize the space which requires extremely advanced technology. May be it is impossible within a human body and we will transform into a strange creature which is half human and half machine to fuse the advantages both of them.
