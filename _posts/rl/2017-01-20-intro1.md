---
title: "Reinforcement Learning: Introduction I"
tags: [rl]
---

### Introduction
This is the first part of a four parts long series about reinforcement learning (hereafter RL). First, I will introduce the different types of machine learning. Then the focus will shift toward RL. I will explain the most important terms and show some examples. The goal of this part is to become more familiar with the core concepts of RL.

### Types of Machine Learning

![blocks](/ai/images/blocks.png "Learning models")
*Different learning models*

The picture above shows the different types of machine learning:

* supervised learning
* unsupervised learning
* reinforcement learning

*Supervised learning* uses the input data and the output data with correct answers. The goal of supervised learning is to find connection between the given inputs and outputs then create a model which can generalize this connection. The outputs for new inputs can be determined by the learnt model. Supervised learning has basically 2 types: classification and regression. In classification the output is a label which represents a class where the input belongs. For example the inputs can be images from handwritten numbers and the outputs are the concrete numbers the images show. In case of regression the output is a continuous value. For instance the input can be the properties of a house - size, where it is, age etc. - and the output is the price of tha house.

The learning is an iterative procedure and it is based on a so called loss function which depends on the differences between the right solution and the prediction of the model. The model is corrected during the iteration according to the losses.

*Unsupervised learning* uses only the input data. The right solutions are not known during learning. The goal is to find patterns, inner structures in the data. Most of the time this means to find clusters: chunks of data which are closely related to each other in some way. This is the so called clustering. The importance of unsupervised learning is that most of the available data is unlabelled. 

*Reinforcement learning* provides a much general learning model. This learning model is also very similar to the way how animals and humans learn. It makes possible to interact with the environment and collect further information on-the-fly. In the subsequent sections this will be covered in details.

### RL basics


$$
....\ \rightarrow\ s_t,\ \rightarrow\ a_t,\ \rightarrow\ r_{t+1},\ \rightarrow\ s_{t+1},\ \rightarrow\ a_{t+1},\ \rightarrow\ r_{t+2}\ \rightarrow\ s_{t+2}\ ....
$$

The discounted return is defined as:

\begin{equation}
   G_t = \sum^\infty_{k=0}{\gamma^k R_{t+1+k}}
\end{equation}

Where $\gamma$ is the so called discounting factor. 

The state-value function is defined as:

\begin{equation}
   v_\pi(s) = \textbf{E}_\pi \left{ \sum^\infty_{k=0}{\gamma^k R_{1+k}} | s_0 = s \right}
\end{equation}

The action-state value is similar as well:

\begin{equation}
   q_\pi(s, a) = \textbf{E}_\pi \left{ \sum^\infty_{k=0}{\gamma^k R_{1+k}} | s_0 = s, a_0 = a \right}
\end{equation}


<a href="https://github.com/adamtiger/ai/tree/code" target="_blank" class="btn btn-success"><i class="fa fa-github fa-lg"></i> View on GitHub</a>




